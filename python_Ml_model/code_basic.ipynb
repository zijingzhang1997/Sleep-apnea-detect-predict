{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. \tBasic Machine learning models\n",
    "#{(1,2),(1,3),(1,4),(2,3),(2,4),(3,4)} are divided into 6 classes labelled into [0, 5]. \n",
    "\n",
    "# import raw train test audio files \n",
    "Folder = r'C:\\Users\\zz587-admin\\Documents\\lecutures\\ECE 4200 2021\\kaggle\\spoken-digit-pair-recognition'\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import pandas\n",
    "train_data=[]\n",
    "test_data=[]\n",
    "for i in range (90000):\n",
    "    rate,data = wavfile.read(Folder + r'\\train\\train_new\\train_' + str(i)+'.wav')\n",
    "    data = np.array(data)\n",
    "    train_data.append(data)\n",
    "\n",
    "for i in range (24750):\n",
    "    rate,data_temp = wavfile.read(Folder + r'\\test\\test_new\\test_' + str(i)+'.wav')\n",
    "    data_temp = np.array(data_temp)\n",
    "    test_data.append(data_temp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate class  from csv file for all training cases \n",
    "\n",
    "Trainfile = pandas.read_csv(Folder + r'\\train.csv')\n",
    "Trainfile.loc[Trainfile['Label'] == 21, 'class'] = 0\n",
    "Trainfile.loc[Trainfile['Label'] == 31, 'class'] = 1\n",
    "Trainfile.loc[Trainfile['Label'] == 41, 'class'] = 2\n",
    "Trainfile.loc[Trainfile['Label'] == 32, 'class'] = 3\n",
    "Trainfile.loc[Trainfile['Label'] == 42, 'class'] = 4\n",
    "Trainfile.loc[Trainfile['Label'] == 43, 'class'] = 5\n",
    "\n",
    "y_train_all = Trainfile['class'].astype('int')\n",
    "y_train_all=np.array(y_train_all) \n",
    "train_data=np.array(train_data)\n",
    "test_data=np.array(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing : tranform by FFT \n",
    "from sklearn import preprocessing\n",
    "from scipy import signal\n",
    "train_data_fft=[]\n",
    "test_data_fft=[]\n",
    "for i in range (90000):\n",
    "    _, Pxx_den = signal.periodogram(train_data[i,:], rate)\n",
    "    train_data_fft.append(Pxx_den)\n",
    "\n",
    "for i in range (24750):\n",
    "    _, Pxx_den = signal.periodogram(test_data[i,:], rate)\n",
    "    test_data_fft.append(Pxx_den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing : Standard  Scaler \n",
    "train_data_scaler=preprocessing.StandardScaler().fit(train_data)\n",
    "test_data_scaler=preprocessing.StandardScaler().fit(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FFT transformed data \n",
    "train_data_fft=np.array(train_data_fft) \n",
    "test_data_fft=np.array(test_data_fft) \n",
    "np.save('fft_train_data.npy',train_data_fft)\n",
    "np.save('fft_test_data.npy',test_data_fft)\n",
    "np.save('y_train_data.npy',y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import FFT transformed data \n",
    "import numpy as np\n",
    "train_data_fft=np.load('fft_train_data.npy')\n",
    "test_data_fft=np.load('fft_test_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 29700 points : 0\n",
      "accuracy 1 \n"
     ]
    }
   ],
   "source": [
    "# split all training cases into training and testing part. \n",
    "# get testing accuracy to evaluate the performance by different ML models \n",
    "# LogisticRegression,DecisionTree,svm,GaussianNB,RandomForest,xgboost are tried \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import xgboost as xgb\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_fft, y_train_all, test_size=0.33)\n",
    "\n",
    "clf1 = LogisticRegression(random_state=0,C=0.7,max_iter=10000)\n",
    "clf2 = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "clf3 = GaussianNB()\n",
    "clf4= svm.SVC(kernel=\"linear\", C=0.7)\n",
    "clf5 = RandomForestClassifier(random_state=0)\n",
    "clf6 = BaggingClassifier(base_estimator=clf1,n_estimators=10, random_state=0)\n",
    "\n",
    "clf7 = xgb.XGBClassifier(n_estimators=5)\n",
    " \n",
    "# clf=clf7.fit(X_train, y_train)\n",
    "# y_pred_test = clf.predict(X_test)\n",
    "model=clf1.fit(X_train, y_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "y_pred_test=np.array(y_pred_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"      % (X_test.shape[0], (y_test != y_pred_test).sum()))\n",
    "print(\"accuracy %d \"      %  float((y_test == y_pred_test).sum()/X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold validation over all training data \n",
    "# get average accuracy over all training data \n",
    "# test on LogisticRegression,DecisionTree,svm,GaussianNB \n",
    "# Output is presented in report \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "def kFoldCV (x,y,model):\n",
    "    x=train_data_fft\n",
    "    y=y_train_all\n",
    "    \n",
    "    rkf = KFold(n_splits=3)\n",
    "    acc_all=[]\n",
    "\n",
    "    for train_ind, test_ind in rkf.split(x,y):\n",
    "        X_train=x[train_ind] \n",
    "        X_test=x[test_ind]\n",
    "        y_train=y[train_ind] \n",
    "        y_test=y[test_ind]\n",
    "        model_fitted=model.fit(X_train, y_train)\n",
    "        y_pred_test =model_fitted.predict(X_test)\n",
    "        acc=float((y_test == y_pred_test).sum()/X_test.shape[0])\n",
    "        acc_all.append(acc)\n",
    "    acc_all=np.array(acc_all)\n",
    "    acc_mean=np.mean(acc_all)\n",
    "    return acc_mean\n",
    "\n",
    "x=train_data_fft\n",
    "y=y_train_all\n",
    "\n",
    "model_LogReg = LogisticRegression(random_state=0,C=0.7,max_iter=10000)\n",
    "model_tree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "model_NB = GaussianNB()\n",
    "model_svm= svm.SVC(kernel=\"linear\", C=0.7)\n",
    "acc_LogReg=kFoldCV(x,y,model_LogReg)\n",
    "acc_NB=kFoldCV(x,y,model_NB)\n",
    "acc_tree=kFoldCV(x,y,model_tree)\n",
    "acc_svm=kFoldCV(x,y,model_svm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally output results using trained mode on new testing data \n",
    "\n",
    "\n",
    "def outputCSV(model,x_train,y_train,x_test,Name):\n",
    "    \n",
    "    y_test_new=model.fit(x_train, y_train_all).predict(x_test)\n",
    "    \n",
    "    y_test_new=np.array(y_test_new)\n",
    "    \n",
    "    label=np.zeros((24750,1))\n",
    "    #label=np.zeros((27250,1))\n",
    "\n",
    "\n",
    "    label[y_test_new==0]=21\n",
    "    label[y_test_new==1]=31\n",
    "    label[y_test_new==2]=41\n",
    "    label[y_test_new==3]=32\n",
    "    label[y_test_new==4]=42\n",
    "    label[y_test_new==5]=43\n",
    "\n",
    "\n",
    "    import csv\n",
    "\n",
    "    with open(Name+'.csv', 'w', newline='') as file:\n",
    "        fieldnames = ['ID', 'Label']\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for i in range(24750):\n",
    "            writer.writerow({'ID': i, 'Label': int(label[i])})\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputCSV(model_LogReg,x,y,test_data_fft,'LogReg1')\n",
    "# outputCSV(model_svm,x,y,test_data_fft,'svm1')\n",
    "outputCSV(model_tree,x,y,test_data_fft,'tree1')\n",
    "outputCSV(model_NB,x,y,test_data_fft,'NB1')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dfcdd2df89cf84bf863a3eee1a8513725fc78c2bc0847c4e28a5df2ed2f4e890"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
